
import os
import re

def generate_h_file(func, type_name, type_type, path_name):
    obj_type = type_name + type_type

    filename = os.path.join(path_name, "G" + obj_type + "Kernel.h")
    f = open(filename, "w+")

    f.write("#ifndef G"+ obj_type.upper() + "KERNEL_H\n")
    f.write("#define G"+ obj_type.upper() + "KERNEL_H\n")
    f.write("\n")
    f.write('#include "' + "G" + obj_type + ".h" +  '"\n')
    f.write('\n')

    f.write("__global void find_" + type_name.lower() + "_" + type_type.lower() + "(" + "G" + obj_type + " *d_neurons, int num, int start_id);")
    f.write("\n")
    f.write("__global void update_" + type_name.lower() + "_" + type_type.lower() + "(" + "G" + obj_type + " *d_neurons, int num, int start_id);")
    f.write("\n")

    f.write("#endif /* " + obj_type.upper() + "_H */\n")

    f.close()


def generate_cu_file(func, type_name, type_type, path_name):
    obj_type = type_name + type_type

    filename = os.path.join(path_name, "G" + obj_type + "Kernel.cu")
    f = open(filename, "w+")

    f.write("\n")
    f.write('#include "../../gpu_utils/runtime.h"\n')
    f.write('\n')
    f.write('#include "' + "G" + obj_type + "Kernel.h" +  '"\n')
    f.write('\n')

    
    f.write("__global void find_" + type_name.lower() + "_" + type_type.lower() + "(" + "G" + obj_type + " *d_neurons, int num, int start_id)\n{\n")
    f.write("\t__shared__ int active_table_t[MAXBLOCKSIZE];\n")
    f.write("\t__shared__ volatile int active_cnt;\n")
    f.write("\n")
    
    f.write("\tif (threadIdx.x == 0) {\n")
    f.write("\t\tactive_cnt = 0;\n")
    f.write("\t}\n")
    f.write("\t__syncthreads();\n")
    f.write("\n")

    f.write("\tint tid = blockIdx.x * blockDim.x + threadIdx.x;\n")
    f.write("\tfor (int idx = tid; idx < num; idx += blockDim.x * gridDim.x) {\n")
    f.write("\t\tint test_loc = 0;\n")
    f.write("\t\t\n")
    f.write("\t\tbool actived = d_neurons->p_refrac_step[idx] <= 0;\n")
    f.write("\t\t\n")
    f.write("\t\tif (actived) {\n")
    f.write("\t\t\ttest_loc = atomicAdd((int*)&active_cnt, 1);\n")
    f.write("\t\t\tif (test_loc < MAXBLOCKSIZE) {\n")
    f.write("\t\t\t\tactive_table_t[test_loc] = idx;\n")
    f.write("\t\t\t\tactived = false;\n")
    f.write("\t\t\t}\n")
    f.write("\t\t} else {\n")
    f.write("\t\t\tgNeuronInput[start_id + idx] = 0;\n")
    f.write("\t\t\tgNeuronInput_I[start_id + idx] = 0;\n")
    f.write("\t\t\td_neurons->p_refrac_step[idx] = d_neurons->p_refrac_step[idx] - 1;\n")
    f.write("\t\t}\n")
    f.write("\t\t__syncthreads();\n")
    f.write("\t\t\n")
    f.write("\t\tif (active_cnt >= MAXBLOCKSIZE) {\n")
    f.write("\t\t\tcommit2globalTable(active_table_t, MAXBLOCKSIZE, gActiveTable, &gActiveTableSize, 0);\n")
    f.write("\t\t\tif (threadIdx.x == 0) {\n")
    f.write("\t\t\t\tactive_cnt = 0;\n")
    f.write("\t\t\t}\n")
    f.write("\t\t}\n")
    f.write("\t\t__syncthreads();\n")
    f.write("\t\t\n")
    f.write("\t\tif (actived) {\n")
    f.write("\t\t\ttest_loc = atomicAdd((int*)&active_cnt, 1);\n")
    f.write("\t\t\tif (test_loc < MAXBLOCKSIZE) {\n")
    f.write("\t\t\t\tactive_table_t[test_loc] = idx;\n")
    f.write("\t\t\t\tactived = false;\n")
    f.write("\t\t\t}\n")
    f.write("\t\t}\n")
    f.write("\t\t__syncthreads();\n")
    f.write("\t\tif (active_cnt >= MAXBLOCKSIZE) {\n")
    f.write("\t\t\tcommit2globalTable(active_table_t, MAXBLOCKSIZE, gActiveTable, &gActiveTableSize, 0);\n")
    f.write("\t\t\tif (threadIdx.x == 0) {\n")
    f.write("\t\t\t\tactive_cnt = 0;\n")
    f.write("\t\t\t}\n")
    f.write("\t\t}\n")
    f.write("\t\t__syncthreads();\n")
    f.write("\t\tif (active_cnt > 0) {\n")
    f.write("\t\t\tcommit2globalTable(active_table_t, active_cnt, gActiveTable, &gActiveTableSize, 0);\n")
    f.write("\t\t\tif (threadIdx.x == 0) {\n")
    f.write("\t\t\t\tactive_cnt = 0;\n")
    f.write("\t\t\t}\n")
    f.write("\t\t}\n")
    f.write("\t\t__syncthreads();\n")
    f.write("\t}\n")
    f.write("}\n")
    f.write("\n")
    f.write("\n")


    f.write("__global void update_" + type_name.lower() + "_" + type_type.lower() + "(" + "G" + obj_type + " *d_neurons, int num, int start_id)\n{\n")
    f.write("\t__shared__ int fire_table_t[MAXBLOCKSIZE];\n")
    f.write("\t__shared__ volatile int fire_cnt;\n")
    f.write("\t\n")

    f.write("\tif (threadIdx.x == 0) {\n")
    f.write("\t\tfire_cnt = 0;\n")
    f.write("\t}\n")
    f.write("\t__syncthreads();\n")
    f.write("\t\n")

    f.write("\tint tid = blockIdx.x * blockDim.x + threadIdx.x;\n")
    f.write("\tfor (int idx = tid; idx < gActiveTableSize; idx +=blockDim.x*gridDim.x) {\n")
    f.write("\t\tbool fired = false;\n")
    f.write("\t\tint test_loc = 0;\n")
    f.write("\t\t\n")
    f.write("\t\tint nid = gActiveTable[idx];\n")
    f.write("\t\tint gnid = start_id + nid; \n")
    f.write("\t\t\n")

    f.write("\t\td_neurons->p_vm[nid] = d_neurons->p_Cm[nid] * d_neurons->p_vm[nid] + d_neurons->p_v_tmp[nid] + d_neurons->p_i_E[nid] * d_neurons->p_C_E[nid] + d_neurons->p_i_I[nid] * d_neurons->p_C_I[nid];\n")
    f.write("\t\t\n")
    f.write("\t\td_neurons->p_i_E[nid] *= d_neurons->p_CE[nid];\n")
    f.write("\t\td_neurons->p_i_I[nid] *= d_neurons->p_CI[nid];\n")
    f.write("\t\t\n")
    f.write("\t\tfired = d_neurons->p_vm[nid] >= d_neurons->p_v_thresh[nid];\n")
    f.write("\t\t\n")
    f.write("\t\tgFireCount[gnid] += fired;\n")
    f.write("\t\t\n")
    f.write("\t\tif (fired) {\n")
    f.write("\t\t\ttest_loc = atomicAdd((int*)&fire_cnt, 1);\n")
    f.write("\t\t\tif (test_loc < MAXBLOCKSIZE) {\n")
    f.write("\t\t\t\tfire_table_t[test_loc] = gnid;\n")
    f.write("\t\t\t\tfired = false;\n")
    f.write("\t\t\t}\n")
    f.write("\t\t\t\n")
    f.write("\t\t\td_neurons->p_refrac_step[nid] = d_neurons->p_refrac_time[nid] - 1;\n")
    f.write("\t\t\td_neurons->p_vm[nid] = d_neurons->p_v_reset[nid];\n")
    f.write("\t\t} else {\n")
    f.write("\t\t\tgXInput[gnid] += gNeuronInput[gnid] + gNeuronInput_I[gnid];\n")
    f.write("\t\t\td_neurons->p_i_E[nid] += gNeuronInput[gnid];\n")
    f.write("\t\t\td_neurons->p_i_I[nid] += gNeuronInput_I[gnid];\n")
    f.write("\t\t}\n")
    f.write("\t\t\n")
    f.write("\t\tgNeuronInput[gnid] = 0;\n")
    f.write("\t\tgNeuronInput_I[gnid] = 0;\n")
    f.write("\t\t__syncthreads();\n")
    f.write("\t\t\n")

    f.write("\t\tif (fire_cnt >= MAXBLOCKSIZE) {\n")
    f.write("\t\t\tcommit2globalTable(fire_table_t, MAXBLOCKSIZE, g_fired_table, &g_fired_tableSizes[gCurrentIdx], g_fired_tableCap*gCurrentIdx);\n")
    f.write("\t\t\tif (threadIdx.x == 0) {\n")
    f.write("\t\t\t\tfire_cnt = 0;\n")
    f.write("\t\t\t}\n")
    f.write("\t\t}\n")
    f.write("\t\t__syncthreads();\n")
    f.write("\t\t\n")

    f.write("\t\tif (fired) {\n")
    f.write("\t\t\ttest_loc = atomicAdd((int*)&fire_cnt, 1);\n")
    f.write("\t\t\tif (test_loc < MAXBLOCKSIZE) {\n")
    f.write("\t\t\t\tfire_table_t[test_loc] = gnid;\n")
    f.write("\t\t\t\tfired = false;\n")
    f.write("\t\t\t}\n")
    f.write("\t\t}\n")
    f.write("\t\t__syncthreads();\n")
    f.write("\t\tif (fire_cnt >= MAXBLOCKSIZE) {\n")
    f.write("\t\t\tcommit2globalTable(fire_table_t, MAXBLOCKSIZE, g_fired_table, &g_fired_tableSizes[gCurrentIdx], g_fired_tableCap*gCurrentIdx);\n")
    f.write("\t\t\tif (threadIdx.x == 0) {\n")
    f.write("\t\t\t\tfire_cnt = 0;\n")
    f.write("\t\t\t}\n")
    f.write("\t\t}\n")
    f.write("\t\t__syncthreads();\n")
    f.write("\t\t\n")
    f.write("\t\tif (fire_cnt > 0) {\n")
    f.write("\t\t\tcommit2globalTable(fire_table_t, fire_cnt, g_fired_table, &g_fired_tableSizes[gCurrentIdx], g_fired_tableCap*gCurrentIdx);\n")
    f.write("\t\t\tif (threadIdx.x == 0) {\n")
    f.write("\t\t\t\tfire_cnt = 0;\n")
    f.write("\t\t\t}\n")
    f.write("\t\t}\n")
    f.write("\t\t\n")
    f.write("\t}\n")

    f.write("}\n")


    f.close()

